# Obsidian 语音助手插件使用说明文档

## 目录
- [项目概述](#项目概述)
- [目录结构](#目录结构)
- [核心功能模块](#核心功能模块)
- [运行环境要求](#运行环境要求)
- [安装步骤](#安装步骤)
- [配置说明](#配置说明)
- [使用方法](#使用方法)
- [API接口说明](#api接口说明)
- [常见问题解答](#常见问题解答)
- [开发者指南](#开发者指南)

## 项目概述

**Obsidian 语音助手插件** 是一个功能完整的语音交互插件，为 Obsidian 笔记软件提供智能语音助手功能。该插件集成了语音识别、语音合成、语音唤醒和多种大语言模型，支持自然语言对话、语音听写、语音朗读等功能。

### 主要特性
- 🎤 **语音识别**：基于讯飞在线ASR，支持实时语音转文字
- 🔊 **语音合成**：基于讯飞在线TTS，支持多种音色和语音参数调节
- 🎯 **语音唤醒**：支持自定义唤醒词，免手动激活
- 🤖 **多模型支持**：集成Google AI Studio、OpenRouter、讯飞星火等多种大语言模型
- 📝 **智能对话**：支持持续对话模式和自定义提示词
- ✍️ **语音听写**：支持连续语音听写，自动插入笔记
- 📖 **语音朗读**：支持选中文本的语音朗读功能
- ⚙️ **高度可配置**：丰富的配置选项，满足不同使用需求

## 目录结构

```
obsidian-yuhanbo-voice_assistant/
├── main.ts                    # 主插件文件，包含所有核心功能
├── main.js                    # 编译后的JavaScript文件
├── manifest.json              # 插件清单文件
├── data.json                  # 用户配置数据文件
├── package.json               # 项目依赖和脚本配置
├── package-lock.json          # 依赖版本锁定文件
├── tsconfig.json              # TypeScript编译配置
├── esbuild.config.mjs         # ESBuild打包配置
├── styles.css                 # 插件样式文件
├── version-bump.mjs           # 版本更新脚本
├── versions.json              # 版本历史记录
├── .gitignore                 # Git忽略文件配置
└── README.md                  # 项目说明文件
```

## 核心功能模块

### 1. 主插件类 (VoiceAssistantPlugin)
- **文件位置**: `main.ts` (第131行开始)
- **功能**: 插件的核心控制器，管理所有语音功能
- **主要属性**:
  - `settings`: 插件配置管理
  - `mediaRecorder`: 音频录制器
  - `wakeMediaRecorder`: 唤醒监听录制器
  - `statusFloat`: 状态浮窗显示
  - `conversationHistory`: 对话历史记录

### 2. 语音识别模块
- **核心方法**: `speechToText()`, `xunfeiOnlineASR()`
- **功能**: 将音频转换为文字，支持讯飞在线ASR
- **输入**: 音频Blob对象
- **输出**: 识别的文字字符串

### 3. 语音合成模块
- **核心方法**: `textToSpeech()`, `xunfeiOnlineTTS()`
- **功能**: 将文字转换为语音并播放
- **支持格式**: MP3音频流
- **可配置参数**: 音色、语速、音量、音调

### 4. 语音唤醒模块
- **核心方法**: `startWakeListening()`, `startWakeListeningLoop()`
- **功能**: 持续监听预设唤醒词，自动激活对话
- **唤醒词**: 可自定义，默认包含"你好，小三"等
- **检测间隔**: 可配置，默认900毫秒

### 5. 大语言模型集成
- **支持的模型**:
  - Google AI Studio (Gemini系列)
  - OpenRouter (GPT、Claude等)
  - 讯飞星火 (Spark系列)
  - 自定义模型
- **核心方法**: `callLLM()`, `callGoogleAI()`, `callOpenRouter()`, `callXunfeiSpark()`

### 6. 对话管理模块
- **持续对话**: 支持多轮对话，自动管理上下文
- **对话历史**: 自动保存对话记录到指定文件夹
- **语音打断**: 支持语音打断TTS播放
- **自定义提示词**: 支持触发词激活特定提示模板

### 7. 语音听写模块
- **核心方法**: `startVoiceDictation()`, `startContinuousDictation()`
- **功能**: 连续语音转文字，自动插入当前笔记
- **静默检测**: 自动检测语音停顿，分段处理
- **实时插入**: 识别结果实时插入光标位置

### 8. 设置界面模块
- **类名**: `VoiceAssistantSettingTab`
- **功能**: 提供图形化配置界面
- **配置项**: 包含所有功能的详细配置选项

## 运行环境要求

### 基础环境
- **Obsidian**: 版本 0.15.0 或更高
- **操作系统**: Windows、macOS、Linux (仅桌面版)
- **网络连接**: 需要稳定的互联网连接（用于在线语音服务和AI模型调用）

### 开发环境
- **Node.js**: 16.0 或更高版本
- **npm**: 6.0 或更高版本
- **TypeScript**: 4.7.4
- **ESBuild**: 0.17.3

### 依赖库
```json
{
  "dependencies": {
    "crypto-js": "^4.2.0",
    "ws": "^8.18.3"
  },
  "devDependencies": {
    "@types/crypto-js": "^4.2.2",
    "@types/node": "^16.11.6",
    "typescript": "4.7.4",
    "esbuild": "0.17.3",
    "obsidian": "latest"
  }
}
```

## 安装步骤

### 方法一：手动安装
1. **下载插件文件**
   ```bash
   git clone https://github.com/yuhanbo/obsidian-yuhanbo-voice_assistant.git
   ```

2. **安装依赖**
   ```bash
   cd obsidian-yuhanbo-voice_assistant
   npm install
   ```

3. **编译插件**
   ```bash
   npm run build
   ```

4. **复制到Obsidian插件目录**
   ```bash
   # 将整个文件夹复制到：
   # Windows: %APPDATA%\Obsidian\plugins\
   # macOS: ~/Library/Application Support/obsidian/plugins/
   # Linux: ~/.config/obsidian/plugins/
   ```

### 方法二：开发模式安装
1. **克隆到Obsidian插件目录**
   ```bash
   cd /path/to/obsidian/vault/.obsidian/plugins/
   git clone https://github.com/yuhanbo/obsidian-yuhanbo-voice_assistant.git
   ```

2. **安装并构建**
   ```bash
   cd obsidian-yuhanbo-voice_assistant
   npm install
   npm run build
   ```

3. **在Obsidian中启用插件**
   - 打开 Obsidian 设置
   - 进入"第三方插件"
   - 找到"语音助手 (Voice Assistant)"
   - 点击启用

## 配置说明

### 基础配置文件 (data.json)

```json
{
  "llmProvider": "xunfei",           // 大语言模型提供商
  "wakeMode": "online",              // 唤醒模式：online/disabled
  "wakeWords": [                     // 自定义唤醒词
    "你好，小三",
    "小三同学", 
    "小三小三"
  ],
  "ttsMode": "online",               // TTS模式：online/disabled
  "asrProvider": "xunfei",           // ASR提供商
  "enableDebugLog": true             // 是否启用调试日志
}
```

### 详细配置项说明

#### 1. 大语言模型配置
```typescript
interface LLMConfig {
  llmProvider: 'google' | 'openrouter' | 'xunfei' | 'custom';
  googleApiKey: string;              // Google AI Studio API密钥
  googleModel: string;               // Google模型名称
  openrouterApiKey: string;          // OpenRouter API密钥
  openrouterModel: string;           // OpenRouter模型名称
  xunfeiAppId: string;               // 讯飞应用ID
  xunfeiApiKey: string;              // 讯飞API密钥
  xunfeiApiSecret: string;           // 讯飞API密钥
  xunfeiModel: string;               // 讯飞模型版本
}
```

#### 2. 语音功能配置
```typescript
interface VoiceConfig {
  // 语音识别
  asrProvider: 'xunfei';
  
  // 语音合成
  ttsMode: 'disabled' | 'online';
  ttsProvider: 'xunfei';
  ttsVoice: string;                  // 音色选择
  ttsSpeed: number;                  // 语速 (0-100)
  ttsVolume: number;                 // 音量 (0-100)
  ttsPitch: number;                  // 音调 (0-100)
  
  // 语音唤醒
  wakeMode: 'online' | 'disabled';
  wakeWords: string[];               // 唤醒词列表
  autoEnterDialogAfterWake: boolean; // 唤醒后自动进入对话
  wakeDetectionInterval: number;     // 检测间隔(毫秒)
}
```

#### 3. 对话功能配置
```typescript
interface DialogConfig {
  continuousDialogDuration: number;     // 持续对话时长(秒)
  showDialogControls: boolean;          // 显示对话控制界面
  conversationSaveFolder: string;       // 对话保存文件夹
  enableVoiceInterruption: boolean;     // 启用语音打断
  customPrompts: Array<{                // 自定义提示词
    name: string;
    trigger: string;
    prompt: string;
    enabled: boolean;
  }>;
}
```

## 使用方法

### 1. 基础语音对话
```typescript
// 通过命令面板启动
// 1. 按 Ctrl+P (Cmd+P) 打开命令面板
// 2. 输入 "开始对话"
// 3. 点击开始语音对话

// 或通过代码调用
this.startVoiceConversation();
```

### 2. 语音唤醒使用
```typescript
// 配置唤醒词
const wakeWords = ["你好，小三", "小三同学", "小三小三"];

// 启动唤醒监听
this.startWakeListening();

// 说出唤醒词后自动激活对话
// 无需手动操作，插件会自动响应
```

### 3. 语音听写功能
```typescript
// 启动语音听写
this.startVoiceDictation();

// 持续听写模式
this.startContinuousDictation();

// 听写内容会自动插入到当前光标位置
```

### 4. 语音朗读功能
```typescript
// 选中文本后启动朗读
this.startVoiceReading();

// 支持暂停/继续/停止控制
this.toggleTTSPlayback();  // 暂停/继续
this.stopTTS();            // 停止朗读
```

### 5. 自定义提示词使用
```typescript
// 在对话中使用触发词
// 例如：说 "提醒我明天开会"
// 会自动应用"任务提醒"提示词模板
```

### 6. 测试功能
插件提供了多个测试方法，可在设置界面的"测试功能"区域使用：

```typescript
// 测试语音识别
await this.testOnlineASR();

// 测试语音合成
await this.testOnlineTTS();

// 测试所有音色
await this.testAllVoiceSpeakers();

// 调试TTS连接
await this.debugTTSConnection();
```

## API接口说明

### 核心API方法

#### 1. 语音识别API
```typescript
/**
 * 语音转文字
 * @param audioBlob 音频数据
 * @returns Promise<string> 识别结果
 */
async speechToText(audioBlob: Blob): Promise<string>

/**
 * 讯飞在线ASR
 * @param audioBlob 音频数据  
 * @returns Promise<string> 识别结果
 */
async xunfeiOnlineASR(audioBlob: Blob): Promise<string>
```

#### 2. 语音合成API
```typescript
/**
 * 文字转语音
 * @param text 要合成的文字
 * @returns Promise<void>
 */
async textToSpeech(text: string): Promise<void>

/**
 * 讯飞在线TTS
 * @param text 要合成的文字
 * @returns Promise<void>
 */
async xunfeiOnlineTTS(text: string): Promise<void>
```

#### 3. 大语言模型API
```typescript
/**
 * 调用大语言模型
 * @param text 用户输入文本
 * @returns Promise<string> AI回复
 */
async callLLM(text: string): Promise<string>

/**
 * 调用Google AI
 * @param text 用户输入
 * @returns Promise<string> AI回复
 */
async callGoogleAI(text: string): Promise<string>

/**
 * 调用讯飞星火
 * @param text 用户输入
 * @returns Promise<string> AI回复  
 */
async callXunfeiSpark(text: string): Promise<string>
```

#### 4. 唤醒监听API
```typescript
/**
 * 启动语音唤醒监听
 */
startWakeListening(): void

/**
 * 停止语音唤醒监听
 */
stopWakeListening(): void

/**
 * 唤醒词检测回调
 */
async onWakeWordDetected(): Promise<void>
```

### 事件回调

#### 1. 录音事件
```typescript
// 录音开始
mediaRecorder.onstart = () => {
  this.updateStatusFloat('🎤 正在录音...', 'info');
};

// 录音数据可用
mediaRecorder.ondataavailable = (event: BlobEvent) => {
  if (event.data.size > 0) {
    this.audioChunks.push(event.data);
  }
};

// 录音停止
mediaRecorder.onstop = () => {
  // 处理录音数据
};
```

#### 2. WebSocket事件
```typescript
// TTS WebSocket连接
ws.onopen = () => {
  console.log('TTS WebSocket连接已建立');
};

ws.onmessage = (event: MessageEvent) => {
  // 处理TTS音频数据
};

ws.onerror = (error) => {
  console.error('TTS WebSocket错误:', error);
};
```

## 常见问题解答

### Q1: 插件无法启动或加载失败？
**A**: 检查以下几点：
1. 确保Obsidian版本 ≥ 0.15.0
2. 检查插件文件是否完整
3. 查看控制台是否有错误信息
4. 尝试重新编译插件：`npm run build`

### Q2: 语音识别不准确或无响应？
**A**: 可能的解决方案：
1. 检查麦克风权限是否已授予
2. 确保网络连接稳定
3. 验证讯飞API密钥是否正确配置
4. 尝试调整录音参数（采样率、声道数）
5. 在安静环境中测试

### Q3: 语音合成无声音或播放失败？
**A**: 排查步骤：
1. 检查系统音量设置
2. 验证讯飞TTS配置是否正确
3. 尝试不同的音色设置
4. 检查网络连接状态
5. 查看调试日志获取详细错误信息

### Q4: 唤醒功能不工作？
**A**: 检查配置：
1. 确保 `wakeMode` 设置为 `"online"`
2. 检查唤醒词是否正确配置
3. 验证麦克风权限
4. 调整唤醒检测间隔
5. 在安静环境中清晰说出唤醒词

### Q5: 大语言模型调用失败？
**A**: 验证配置：
1. 检查对应的API密钥是否正确
2. 确认API配额是否充足
3. 验证网络连接和防火墙设置
4. 尝试切换不同的模型提供商
5. 查看调试日志获取具体错误信息

### Q6: 如何自定义唤醒词？
**A**: 在设置界面中：
1. 进入"语音唤醒配置"部分
2. 在"唤醒词管理"中添加新的唤醒词
3. 建议使用3-5个字的清晰词语
4. 避免使用过于常见的词汇

### Q7: 如何添加自定义提示词？
**A**: 配置步骤：
1. 进入插件设置的"自定义提示词"部分
2. 点击"添加新提示词"
3. 设置触发关键词和提示内容
4. 启用该提示词
5. 在对话中使用触发词即可激活

### Q8: 插件占用资源过多？
**A**: 优化建议：
1. 调整唤醒检测间隔（增大数值）
2. 关闭不需要的功能（如语音唤醒）
3. 降低音频采样率
4. 关闭调试日志
5. 定期清理对话历史文件

### Q9: 如何备份和恢复配置？
**A**: 配置管理：
1. 备份：复制 `data.json` 文件
2. 恢复：将备份的 `data.json` 文件覆盖当前配置
3. 重启Obsidian使配置生效
4. 建议定期备份重要配置

### Q10: 如何更新插件？
**A**: 更新步骤：
1. 备份当前配置文件 `data.json`
2. 下载最新版本插件代码
3. 运行 `npm install && npm run build`
4. 恢复配置文件
5. 重启Obsidian

## 开发者指南

### 项目架构

#### 1. 核心类结构
```typescript
// 主插件类
export default class VoiceAssistantPlugin extends Plugin {
  // 配置管理
  settings: VoiceAssistantSettings;
  
  // 音频处理
  private mediaRecorder: MediaRecorder | null;
  private wakeMediaRecorder: MediaRecorder | null;
  
  // 状态管理
  private isRecording: boolean;
  private isListening: boolean;
  private isInContinuousDialog: boolean;
  
  // UI组件
  private statusFloat: HTMLElement | null;
}
```

#### 2. 设置界面类
```typescript
class VoiceAssistantSettingTab extends PluginSettingTab {
  plugin: VoiceAssistantPlugin;
  
  constructor(app: App, plugin: VoiceAssistantPlugin);
  display(): void;  // 渲染设置界面
}
```

### 开发环境搭建

#### 1. 克隆项目
```bash
git clone https://github.com/yuhanbo/obsidian-yuhanbo-voice_assistant.git
cd obsidian-yuhanbo-voice_assistant
```

#### 2. 安装依赖
```bash
npm install
```

#### 3. 开发模式
```bash
# 监听文件变化，自动编译
npm run dev

# 手动编译
npm run build
```

#### 4. 调试技巧
```typescript
// 启用调试日志
this.settings.enableDebugLog = true;

// 使用调试方法
this.debugLog('调试信息', data);

// 浏览器控制台查看日志
// 打开 Obsidian 开发者工具 (Ctrl+Shift+I)
```

### 扩展开发

#### 1. 添加新的语音服务提供商
```typescript
// 1. 扩展配置接口
interface VoiceAssistantSettings {
  asrProvider: 'xunfei' | 'newProvider';
  ttsProvider: 'xunfei' | 'newProvider';
}

// 2. 实现新的ASR方法
async newProviderASR(audioBlob: Blob): Promise<string> {
  // 实现新的语音识别逻辑
}

// 3. 实现新的TTS方法
async newProviderTTS(text: string): Promise<void> {
  // 实现新的语音合成逻辑
}

// 4. 在主方法中添加分支
async speechToText(audioBlob: Blob): Promise<string> {
  switch (this.settings.asrProvider) {
    case 'xunfei':
      return await this.xunfeiOnlineASR(audioBlob);
    case 'newProvider':
      return await this.newProviderASR(audioBlob);
  }
}
```

#### 2. 添加新的大语言模型
```typescript
// 1. 扩展LLM提供商类型
type LLMProvider = 'google' | 'openrouter' | 'xunfei' | 'newLLM';

// 2. 实现新的LLM调用方法
async callNewLLM(text: string): Promise<string> {
  // 实现新的大语言模型调用逻辑
}

// 3. 在主调用方法中添加分支
async callLLM(text: string): Promise<string> {
  switch (this.settings.llmProvider) {
    case 'newLLM':
      return await this.callNewLLM(text);
    // ... 其他分支
  }
}
```

#### 3. 自定义UI组件
```typescript
// 创建自定义状态显示
private createCustomStatusDisplay(): HTMLElement {
  const container = document.createElement('div');
  container.style.cssText = `
    position: fixed;
    top: 20px;
    right: 20px;
    background: var(--background-primary);
    border: 1px solid var(--background-modifier-border);
    border-radius: 8px;
    padding: 12px;
    z-index: 1000;
  `;
  
  return container;
}
```

### 性能优化建议

#### 1. 音频处理优化
```typescript
// 使用Web Workers处理音频
const worker = new Worker('audio-processor.js');
worker.postMessage({ audioData: audioBlob });

// 音频压缩
const compressedAudio = await this.compressAudio(audioBlob);
```

#### 2. 内存管理
```typescript
// 及时清理音频资源
private cleanupAudioResources(): void {
  if (this.currentAudio) {
    this.currentAudio.pause();
    this.currentAudio = null;
  }
  
  this.audioChunks = [];
  this.dictationAudioChunks = [];
}
```

#### 3. 网络请求优化
```typescript
// 添加请求重试机制
async retryRequest<T>(
  requestFn: () => Promise<T>, 
  maxRetries: number = 3
): Promise<T> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await requestFn();
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await new Promise(resolve => setTimeout(resolve, 1000 * (i + 1)));
    }
  }
}
```

### 测试指南

#### 1. 单元测试
```typescript
// 测试语音识别功能
describe('语音识别测试', () => {
  test('应该正确识别音频', async () => {
    const mockAudio = new Blob(['test'], { type: 'audio/wav' });
    const result = await plugin.speechToText(mockAudio);
    expect(result).toBeDefined();
  });
});
```

#### 2. 集成测试
```typescript
// 测试完整对话流程
describe('对话流程测试', () => {
  test('应该完成完整的语音对话', async () => {
    await plugin.startVoiceConversation();
    // 模拟用户语音输入
    // 验证AI响应
    // 验证TTS播放
  });
});
```

### 发布流程

#### 1. 版本更新
```bash
# 更新版本号
npm run version

# 提交更改
git add .
git commit -m "Release v1.x.x"
git tag v1.x.x
git push origin main --tags
```

#### 2. 构建发布版本
```bash
# 生产环境构建
npm run build

# 检查构建文件
ls -la main.js manifest.json styles.css
```

#### 3. 发布到Obsidian社区
1. 创建GitHub Release
2. 上传构建文件
3. 提交到Obsidian插件市场
4. 更新文档和说明

---

## 许可证

本项目采用 MIT 许可证。详见 [LICENSE](LICENSE) 文件。

## 贡献指南

欢迎提交Issue和Pull Request来改进这个项目。在贡献代码前，请确保：

1. 遵循现有的代码风格
2. 添加适当的注释和文档
3. 进行充分的测试
4. 更新相关文档




## 👨‍💻 作者信息

**余汉波** - 编程爱好者-量化交易和效率工具开发

- **GitHub**: [@yuhanbo758](https://github.com/yuhanbo758)

- **Email**: yuhanbo@sanrenjz.com

- **Website**: [三人聚智](https://www.sanrenjz.com)

## 🌐 相关链接

- 🏠 [项目主页](https://www.sanrenjz.com)

- 📚 [在线文档](https://docs.sanrenjz.com)（财经、代码和库文档等）

- 🛒 [插件商店](https://shop.sanrenjz.com)（个人开发的所有程序，包括开源和不开源）


## 联系我们

[联系我们 - 三人聚智-余汉波](https://www.sanrenjz.com/contact_us/)

python 程序管理工具下载：[sanrenjz - 三人聚智-余汉波](https://www.sanrenjz.com/sanrenjz/)

效率工具程序管理下载：[sanrenjz-tools - 三人聚智-余汉波](https://www.sanrenjz.com/sanrenjz-tools/)

![三码合一](https://gdsx.sanrenjz.com/image/sanrenjz_yuhanbolh_yuhanbo758.png?imageSlim&t=1ab9b82c-e220-8022-beff-e265a194292a)

![余汉波打赏码](https://gdsx.sanrenjz.com/image/%E6%89%93%E8%B5%8F%E7%A0%81%E5%90%88%E4%B8%80.png?imageSlim)

## 🙏 致谢

感谢所有为本项目贡献代码和想法的开发者们！

---
**⭐ 如果这个项目对您有帮助，请给它一个 Star！**



